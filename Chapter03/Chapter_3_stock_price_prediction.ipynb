{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 3 - stock price prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5Y3bHRRwG66w",
        "colab_type": "code",
        "outputId": "9b1c741e-6650-4ae9-ba22-05609f19352c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/6fab2uqje8e5bf5/stock_data.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-04 05:48:13--  https://www.dropbox.com/s/6fab2uqje8e5bf5/stock_data.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/6fab2uqje8e5bf5/stock_data.csv [following]\n",
            "--2019-01-04 05:48:13--  https://www.dropbox.com/s/raw/6fab2uqje8e5bf5/stock_data.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce517c10fd655eed4d393f3fd66.dl.dropboxusercontent.com/cd/0/inline/AYvmD-eJiN-yAP6GDyus8JrwgSdjDCVvN5jF7XhRlwb5RT97Qwo2fps6qhaIfQGa4beKlLXwaVDdS8Q8VintPed_uIbMQMcaCjybbtmZQ5y0lSpsESRv2J1yoDcDm7kcQtaMRtIWW3EZpJKkYrlNLwFOABJd66fYSGFxdVQrUgLpavVYbwCkENLtbg8J3ZIUNao/file [following]\n",
            "--2019-01-04 05:48:13--  https://uce517c10fd655eed4d393f3fd66.dl.dropboxusercontent.com/cd/0/inline/AYvmD-eJiN-yAP6GDyus8JrwgSdjDCVvN5jF7XhRlwb5RT97Qwo2fps6qhaIfQGa4beKlLXwaVDdS8Q8VintPed_uIbMQMcaCjybbtmZQ5y0lSpsESRv2J1yoDcDm7kcQtaMRtIWW3EZpJKkYrlNLwFOABJd66fYSGFxdVQrUgLpavVYbwCkENLtbg8J3ZIUNao/file\n",
            "Resolving uce517c10fd655eed4d393f3fd66.dl.dropboxusercontent.com (uce517c10fd655eed4d393f3fd66.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uce517c10fd655eed4d393f3fd66.dl.dropboxusercontent.com (uce517c10fd655eed4d393f3fd66.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169042 (165K) [text/plain]\n",
            "Saving to: ‘stock_data.csv’\n",
            "\n",
            "\rstock_data.csv        0%[                    ]       0  --.-KB/s               \rstock_data.csv       91%[=================>  ] 150.91K   721KB/s               \rstock_data.csv      100%[===================>] 165.08K   786KB/s    in 0.2s    \n",
            "\n",
            "2019-01-04 05:48:14 (786 KB/s) - ‘stock_data.csv’ saved [169042/169042]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PwDDtBaaG9yk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data2 = pd.read_csv('/content/stock_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YNeCh6WaHAUI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x= []\n",
        "y = []\n",
        "for i in range(data2.shape[0]-5):\n",
        " x.append(data2.loc[i:(i+4)]['Close'].values)\n",
        " y.append(data2.loc[i+5]['Close'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKy5nnl2HCSs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.array(x)\n",
        "y = np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_n6WsLHeHG05",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3LPeDekHKEo",
        "colab_type": "code",
        "outputId": "8e78cd55-f7b5-47f2-b324-dc21b2cfb1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "from keras.models import Sequential, Model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim = 5, activation = 'relu'))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 701\n",
            "Trainable params: 701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aQTaFw1QH2PT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0VH_MaksHOsQ",
        "colab_type": "code",
        "outputId": "f68f7d45-db8c-434f-ca6d-86a5e66cd4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test), verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1579 samples, validate on 677 samples\n",
            "Epoch 1/100\n",
            "1579/1579 [==============================] - 2s 1ms/step - loss: 133650.8578 - val_loss: 1510.8221\n",
            "Epoch 2/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 3386.9168 - val_loss: 1551.8139\n",
            "Epoch 3/100\n",
            "1579/1579 [==============================] - 0s 77us/step - loss: 646.6516 - val_loss: 546.1717\n",
            "Epoch 4/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 451.7747 - val_loss: 476.3091\n",
            "Epoch 5/100\n",
            "1579/1579 [==============================] - 0s 74us/step - loss: 441.2901 - val_loss: 455.9048\n",
            "Epoch 6/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 436.7432 - val_loss: 458.0513\n",
            "Epoch 7/100\n",
            "1579/1579 [==============================] - 0s 72us/step - loss: 437.3226 - val_loss: 454.5097\n",
            "Epoch 8/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 439.4474 - val_loss: 452.7269\n",
            "Epoch 9/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 437.5184 - val_loss: 452.0548\n",
            "Epoch 10/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 435.6988 - val_loss: 453.1925\n",
            "Epoch 11/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 435.2134 - val_loss: 461.5284\n",
            "Epoch 12/100\n",
            "1579/1579 [==============================] - 0s 77us/step - loss: 432.4928 - val_loss: 449.8396\n",
            "Epoch 13/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 442.0190 - val_loss: 451.4050\n",
            "Epoch 14/100\n",
            "1579/1579 [==============================] - 0s 72us/step - loss: 436.9298 - val_loss: 449.3152\n",
            "Epoch 15/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 433.2715 - val_loss: 453.3328\n",
            "Epoch 16/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 434.5904 - val_loss: 446.9849\n",
            "Epoch 17/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 429.9436 - val_loss: 445.6353\n",
            "Epoch 18/100\n",
            "1579/1579 [==============================] - 0s 73us/step - loss: 441.7538 - val_loss: 451.9210\n",
            "Epoch 19/100\n",
            "1579/1579 [==============================] - 0s 72us/step - loss: 427.4274 - val_loss: 447.8052\n",
            "Epoch 20/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 427.0232 - val_loss: 442.5060\n",
            "Epoch 21/100\n",
            "1579/1579 [==============================] - 0s 75us/step - loss: 427.2419 - val_loss: 441.7420\n",
            "Epoch 22/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 431.5513 - val_loss: 446.0585\n",
            "Epoch 23/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 424.3902 - val_loss: 448.1073\n",
            "Epoch 24/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 425.7798 - val_loss: 448.4024\n",
            "Epoch 25/100\n",
            "1579/1579 [==============================] - 0s 68us/step - loss: 422.7132 - val_loss: 438.2285\n",
            "Epoch 26/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 420.3980 - val_loss: 444.9930\n",
            "Epoch 27/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 419.8926 - val_loss: 435.4774\n",
            "Epoch 28/100\n",
            "1579/1579 [==============================] - 0s 68us/step - loss: 431.3184 - val_loss: 433.5421\n",
            "Epoch 29/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 433.2942 - val_loss: 433.4200\n",
            "Epoch 30/100\n",
            "1579/1579 [==============================] - 0s 78us/step - loss: 414.1037 - val_loss: 431.3870\n",
            "Epoch 31/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 414.9156 - val_loss: 434.8269\n",
            "Epoch 32/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 417.6392 - val_loss: 442.2685\n",
            "Epoch 33/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 421.7497 - val_loss: 436.9423\n",
            "Epoch 34/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 412.1415 - val_loss: 426.5017\n",
            "Epoch 35/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 424.6894 - val_loss: 428.0960\n",
            "Epoch 36/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 408.5096 - val_loss: 425.5900\n",
            "Epoch 37/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 411.5949 - val_loss: 422.1814\n",
            "Epoch 38/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 404.6171 - val_loss: 425.9592\n",
            "Epoch 39/100\n",
            "1579/1579 [==============================] - 0s 76us/step - loss: 406.9442 - val_loss: 422.2326\n",
            "Epoch 40/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 401.7351 - val_loss: 423.2380\n",
            "Epoch 41/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 403.3018 - val_loss: 420.6035\n",
            "Epoch 42/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 398.6120 - val_loss: 422.2842\n",
            "Epoch 43/100\n",
            "1579/1579 [==============================] - 0s 76us/step - loss: 405.0983 - val_loss: 429.0688\n",
            "Epoch 44/100\n",
            "1579/1579 [==============================] - 0s 68us/step - loss: 420.0243 - val_loss: 468.0874\n",
            "Epoch 45/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 408.5792 - val_loss: 414.7596\n",
            "Epoch 46/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 400.4951 - val_loss: 411.1755\n",
            "Epoch 47/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 407.7053 - val_loss: 409.0062\n",
            "Epoch 48/100\n",
            "1579/1579 [==============================] - 0s 74us/step - loss: 404.2607 - val_loss: 444.5736\n",
            "Epoch 49/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 397.7020 - val_loss: 404.5672\n",
            "Epoch 50/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 388.8078 - val_loss: 403.1042\n",
            "Epoch 51/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 385.0304 - val_loss: 410.0703\n",
            "Epoch 52/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 388.1916 - val_loss: 400.9763\n",
            "Epoch 53/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 396.7685 - val_loss: 427.8689\n",
            "Epoch 54/100\n",
            "1579/1579 [==============================] - 0s 72us/step - loss: 407.0858 - val_loss: 438.0123\n",
            "Epoch 55/100\n",
            "1579/1579 [==============================] - 0s 74us/step - loss: 386.7115 - val_loss: 407.2497\n",
            "Epoch 56/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 379.5385 - val_loss: 393.7500\n",
            "Epoch 57/100\n",
            "1579/1579 [==============================] - 0s 75us/step - loss: 376.9245 - val_loss: 395.2604\n",
            "Epoch 58/100\n",
            "1579/1579 [==============================] - 0s 72us/step - loss: 380.3180 - val_loss: 410.2576\n",
            "Epoch 59/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 380.2616 - val_loss: 407.5248\n",
            "Epoch 60/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 376.2925 - val_loss: 389.0748\n",
            "Epoch 61/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 373.3638 - val_loss: 390.5302\n",
            "Epoch 62/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 390.6439 - val_loss: 386.5832\n",
            "Epoch 63/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 368.2027 - val_loss: 382.6256\n",
            "Epoch 64/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 377.6834 - val_loss: 393.8082\n",
            "Epoch 65/100\n",
            "1579/1579 [==============================] - 0s 72us/step - loss: 367.6053 - val_loss: 390.0003\n",
            "Epoch 66/100\n",
            "1579/1579 [==============================] - 0s 75us/step - loss: 372.1332 - val_loss: 426.3332\n",
            "Epoch 67/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 383.7296 - val_loss: 379.1772\n",
            "Epoch 68/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 361.5856 - val_loss: 374.4878\n",
            "Epoch 69/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 359.2942 - val_loss: 383.8835\n",
            "Epoch 70/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 362.3635 - val_loss: 372.0698\n",
            "Epoch 71/100\n",
            "1579/1579 [==============================] - 0s 72us/step - loss: 367.2990 - val_loss: 392.1939\n",
            "Epoch 72/100\n",
            "1579/1579 [==============================] - 0s 76us/step - loss: 357.2127 - val_loss: 386.6843\n",
            "Epoch 73/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 366.2038 - val_loss: 382.5771\n",
            "Epoch 74/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 358.9135 - val_loss: 366.3847\n",
            "Epoch 75/100\n",
            "1579/1579 [==============================] - 0s 78us/step - loss: 364.2960 - val_loss: 370.4916\n",
            "Epoch 76/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 355.7650 - val_loss: 370.1797\n",
            "Epoch 77/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 360.4167 - val_loss: 383.5847\n",
            "Epoch 78/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 374.7228 - val_loss: 365.5864\n",
            "Epoch 79/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 343.1749 - val_loss: 357.5013\n",
            "Epoch 80/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 338.7155 - val_loss: 387.3912\n",
            "Epoch 81/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 350.0892 - val_loss: 356.3809\n",
            "Epoch 82/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 339.7124 - val_loss: 369.2696\n",
            "Epoch 83/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 355.7055 - val_loss: 365.0375\n",
            "Epoch 84/100\n",
            "1579/1579 [==============================] - 0s 75us/step - loss: 351.3070 - val_loss: 348.9002\n",
            "Epoch 85/100\n",
            "1579/1579 [==============================] - 0s 72us/step - loss: 352.8751 - val_loss: 372.9102\n",
            "Epoch 86/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 331.6297 - val_loss: 348.1086\n",
            "Epoch 87/100\n",
            "1579/1579 [==============================] - 0s 68us/step - loss: 329.9319 - val_loss: 345.6823\n",
            "Epoch 88/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 340.0103 - val_loss: 448.1846\n",
            "Epoch 89/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 336.7051 - val_loss: 345.1589\n",
            "Epoch 90/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 330.4092 - val_loss: 388.6053\n",
            "Epoch 91/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 351.8183 - val_loss: 349.1328\n",
            "Epoch 92/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 329.5237 - val_loss: 339.7139\n",
            "Epoch 93/100\n",
            "1579/1579 [==============================] - 0s 76us/step - loss: 339.8800 - val_loss: 340.8454\n",
            "Epoch 94/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 321.5222 - val_loss: 360.4169\n",
            "Epoch 95/100\n",
            "1579/1579 [==============================] - 0s 69us/step - loss: 317.1154 - val_loss: 331.8280\n",
            "Epoch 96/100\n",
            "1579/1579 [==============================] - 0s 73us/step - loss: 322.7872 - val_loss: 336.0511\n",
            "Epoch 97/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 324.9110 - val_loss: 330.6499\n",
            "Epoch 98/100\n",
            "1579/1579 [==============================] - 0s 71us/step - loss: 329.2064 - val_loss: 339.2840\n",
            "Epoch 99/100\n",
            "1579/1579 [==============================] - 0s 70us/step - loss: 323.5034 - val_loss: 375.0005\n",
            "Epoch 100/100\n",
            "1579/1579 [==============================] - 0s 73us/step - loss: 319.5919 - val_loss: 329.0416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffacbaa1f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "YpUeH2ENZ4Bq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib, json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4pquNhuZ6kv",
        "colab_type": "code",
        "outputId": "a3af0127-ffe1-4930-d6df-edd33ce38358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "dates = []\n",
        "titles = []\n",
        "for i in range(100):\n",
        "  try:\n",
        "    url = 'https://content.guardianapis.com/search?from-date=2010-01-01&section=business&page-size=200&order-by=newest&page='+str(i+1)+'&q=amazon&api-key=207b6047-a2a6-4dd2-813b-5cd006b780d7'\n",
        "    response = urllib.request.urlopen(url)\n",
        "    encoding = response.info().get_content_charset('utf8')\n",
        "    data = json.loads(response.read().decode(encoding))\n",
        "    print(i)\n",
        "    for j in range(len(data['response']['results'])):\n",
        "      dates.append(data['response']['results'][j]['webPublicationDate'])\n",
        "      titles.append(data['response']['results'][j]['webTitle'])  \n",
        "  except:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jOxK0c5rZ9aH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame(dates, titles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulAYpE87Z_a5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = data.reset_index()\n",
        "data.columns = ['title','date']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VbnScL2uaDG3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data['date']=data['date'].str[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Rjxkad6aFAD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data['date']=pd.to_datetime(data['date'], format = '%Y-%m-%d')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hHoLTUIhaGeE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = data.sort_values(by='date')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbNMjcyyaIIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_final = data.groupby('date').first().reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fBH0--RFaJjG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data2['Date'] = pd.to_datetime(data2['Date'],format='%Y-%m-%d')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uHfaYdCYaP6Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data3 = pd.merge(data2,data_final, left_on = 'Date', right_on = 'date', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Aarus3_eJJU",
        "colab_type": "code",
        "outputId": "192a541d-1ee1-44ac-fa97-4b52b1e862ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2261, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "HQAqIWeEd7Eb",
        "colab_type": "code",
        "outputId": "fb1d4cb8-313b-4113-d329-2aa53f02a42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data3.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2261, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "jolqiCJ2aRY_",
        "colab_type": "code",
        "outputId": "dd4ee5f2-88df-4fb6-982a-e63ae460ee40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "stop = nltk.corpus.stopwords.words('english')\n",
        "def preprocess(text):\n",
        "    text = str(text)\n",
        "    text=text.lower()\n",
        "    text=re.sub('[^0-9a-zA-Z]+',' ',text)\n",
        "    words = text.split()\n",
        "    words2=[w for w in words if (w not in stop)]\n",
        "    #words3=[ps.stem(w) for w in words]\n",
        "    words4=' '.join(words2)\n",
        "    return(words4)\n",
        "data3['title'] = data3['title'].apply(preprocess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9OjIfVIwaS5t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data3['title']=np.where(data3['title'].isnull(),'-','-'+data3['title'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pRF-4hRxaUro",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "docs = data3['title'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KwD59MXaWil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counts = Counter()\n",
        "for i,review in enumerate(docs):\n",
        "  counts.update(review.split())\n",
        "words = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_size=len(words)\n",
        "word_to_int = {word: i for i, word in enumerate(words, 1)}\n",
        "encoded_docs = []\n",
        "for doc in docs:\n",
        "  encoded_docs.append([word_to_int[word] for word in doc.split()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36tz3BW7d2K6",
        "colab_type": "code",
        "outputId": "41b30d20-1d29-46ef-9c6d-ddd3f2dba2ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "docs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2261,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "BUxiFUexaX8S",
        "colab_type": "code",
        "outputId": "10a42157-8c59-4fc8-8c59-78770cd426cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "wYP4h4XGaaQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def vectorize_sequences(sequences, dimension=vocab_size):\n",
        "     results = np.zeros((len(sequences), dimension+1))\n",
        "     for i, sequence in enumerate(sequences):\n",
        "         results[i, sequence] = 1.\n",
        "     return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFLitTu1ajnL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorized_docs = vectorize_sequences(encoded_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWHyW9D5ar7H",
        "colab_type": "code",
        "outputId": "714740bd-46af-46d0-c9d1-d9678ea86e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vectorized_docs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2261, 2406)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "nwHdv-PAb4qA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c37f425-6c14-4799-ccf2-8aad5b6453f3"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Input\n",
        "from keras import Model\n",
        "import keras.backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wL6QyRrJbPYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c8dddcf8-835c-4b3d-f32e-bebad4f4c1ef"
      },
      "cell_type": "code",
      "source": [
        "input1 = Input(shape=(2406,))\n",
        "model = (Dense(100, activation='relu'))(input1)\n",
        "model = (Dense(1, activation='tanh'))(model)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1RTER7subvX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input2 = Input(shape=(5,))\n",
        "model2 = (Dense(100, activation='relu'))(input2)\n",
        "model2 = (Dense(1, activation='linear'))(model2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jnfQR81fb_hf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import multiply\n",
        "out = multiply([model, model2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qs6MEvjUcNJm",
        "colab_type": "code",
        "outputId": "5e370681-65c5-401e-8f33-0f817a70db57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model([input1, input2], out)\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 2406)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          240700      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          600         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            101         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            101         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 1)            0           dense_2[0][0]                    \n",
            "                                                                 dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 241,502\n",
            "Trainable params: 241,502\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FlrwKERH5JtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "a9c2009c-e1ac-4d9e-979d-391503445d8e"
      },
      "cell_type": "code",
      "source": [
        "!apt install graphviz\n",
        "!pip install pydot pydot-ng"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pydot-ng in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZXmn76ne52U9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XwkonZju542n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "1c63e454-7172-40e0-c7e8-d7d235bc9645"
      },
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=True, filename='model.png')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv8AAAGVCAIAAADmHgnUAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n8n+Bwe/ldln8fQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 383,
              "height": 202
            }
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "VkrmrAutcP4-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1 = np.array(x)\n",
        "x2 = np.array(vectorized_docs[5:])\n",
        "y = np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NE7-M__VcvBt",
        "colab_type": "code",
        "outputId": "f88a6f18-5a27-4829-9098-c8445cf9862b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(x1.shape, x2.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2256, 5) (2256, 2406) (2256,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DOjQJVBacqXu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X1_train = x1[:2100,:]\n",
        "X2_train = x2[:2100, :]\n",
        "y_train = y[:2100]\n",
        "\n",
        "X1_test = x1[2100:,:]\n",
        "X2_test = x2[2100:,:]\n",
        "y_test = y[2100:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-4FFPDHndnbU",
        "colab_type": "code",
        "outputId": "a4583c98-06fe-424d-e20f-2c3985af876d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(X1_test.shape, X2_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(156, 5) (156, 2406) (156,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RwuITD_-dGni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YTo70qGWc1fJ",
        "colab_type": "code",
        "outputId": "34cd4a5f-7525-43b5-f36b-5b97880921c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13651
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x=[X2_train, X1_train], y=y_train, epochs=400,batch_size = 32, validation_data = ([X2_test, X1_test], y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2100 samples, validate on 156 samples\n",
            "Epoch 1/400\n",
            "2100/2100 [==============================] - 0s 205us/step - loss: 82.9811 - acc: 0.0019 - val_loss: 5740.7854 - val_acc: 0.0000e+00\n",
            "Epoch 2/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 83.9892 - acc: 0.0014 - val_loss: 5148.0213 - val_acc: 0.0000e+00\n",
            "Epoch 3/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 90.1018 - acc: 0.0038 - val_loss: 4459.2365 - val_acc: 0.0000e+00\n",
            "Epoch 4/400\n",
            "2100/2100 [==============================] - 0s 183us/step - loss: 97.0022 - acc: 0.0014 - val_loss: 4608.7379 - val_acc: 0.0000e+00\n",
            "Epoch 5/400\n",
            "2100/2100 [==============================] - 0s 213us/step - loss: 109.7494 - acc: 0.0019 - val_loss: 4663.9670 - val_acc: 0.0000e+00\n",
            "Epoch 6/400\n",
            "2100/2100 [==============================] - 0s 186us/step - loss: 147.1527 - acc: 4.7619e-04 - val_loss: 4358.9167 - val_acc: 0.0000e+00\n",
            "Epoch 7/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 108.1919 - acc: 4.7619e-04 - val_loss: 3542.6667 - val_acc: 0.0000e+00\n",
            "Epoch 8/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 101.3732 - acc: 0.0019 - val_loss: 4723.8136 - val_acc: 0.0000e+00\n",
            "Epoch 9/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 93.0963 - acc: 9.5238e-04 - val_loss: 7377.1325 - val_acc: 0.0000e+00\n",
            "Epoch 10/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 103.7798 - acc: 0.0014 - val_loss: 3533.8353 - val_acc: 0.0000e+00\n",
            "Epoch 11/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 98.3825 - acc: 9.5238e-04 - val_loss: 3609.1093 - val_acc: 0.0000e+00\n",
            "Epoch 12/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 98.7600 - acc: 4.7619e-04 - val_loss: 3277.4988 - val_acc: 0.0000e+00\n",
            "Epoch 13/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 105.2152 - acc: 0.0019 - val_loss: 2932.0433 - val_acc: 0.0000e+00\n",
            "Epoch 14/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 113.8619 - acc: 0.0019 - val_loss: 3236.5358 - val_acc: 0.0000e+00\n",
            "Epoch 15/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 100.9791 - acc: 0.0019 - val_loss: 3522.6784 - val_acc: 0.0000e+00\n",
            "Epoch 16/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 88.9747 - acc: 0.0014 - val_loss: 3244.0333 - val_acc: 0.0000e+00\n",
            "Epoch 17/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 88.1675 - acc: 9.5238e-04 - val_loss: 3424.5743 - val_acc: 0.0000e+00\n",
            "Epoch 18/400\n",
            "2100/2100 [==============================] - 0s 205us/step - loss: 95.2298 - acc: 0.0019 - val_loss: 3008.0201 - val_acc: 0.0000e+00\n",
            "Epoch 19/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 86.4176 - acc: 0.0029 - val_loss: 3193.6300 - val_acc: 0.0000e+00\n",
            "Epoch 20/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 134.5867 - acc: 0.0019 - val_loss: 4116.0256 - val_acc: 0.0000e+00\n",
            "Epoch 21/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 118.9950 - acc: 0.0014 - val_loss: 2662.6922 - val_acc: 0.0000e+00\n",
            "Epoch 22/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 101.8420 - acc: 0.0029 - val_loss: 2340.2723 - val_acc: 0.0000e+00\n",
            "Epoch 23/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 108.6767 - acc: 0.0000e+00 - val_loss: 2642.2679 - val_acc: 0.0000e+00\n",
            "Epoch 24/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 102.4133 - acc: 4.7619e-04 - val_loss: 2536.4146 - val_acc: 0.0000e+00\n",
            "Epoch 25/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 127.6099 - acc: 9.5238e-04 - val_loss: 2707.3639 - val_acc: 0.0000e+00\n",
            "Epoch 26/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 102.5419 - acc: 0.0014 - val_loss: 2905.0220 - val_acc: 0.0000e+00\n",
            "Epoch 27/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 100.8738 - acc: 0.0014 - val_loss: 2385.0834 - val_acc: 0.0000e+00\n",
            "Epoch 28/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 91.7689 - acc: 0.0019 - val_loss: 3326.0161 - val_acc: 0.0000e+00\n",
            "Epoch 29/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 108.3045 - acc: 9.5238e-04 - val_loss: 2625.1041 - val_acc: 0.0000e+00\n",
            "Epoch 30/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 113.9558 - acc: 0.0000e+00 - val_loss: 2936.9531 - val_acc: 0.0000e+00\n",
            "Epoch 31/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 101.7804 - acc: 0.0033 - val_loss: 3198.2782 - val_acc: 0.0000e+00\n",
            "Epoch 32/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 113.3120 - acc: 9.5238e-04 - val_loss: 2737.0921 - val_acc: 0.0000e+00\n",
            "Epoch 33/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 108.8201 - acc: 0.0014 - val_loss: 2297.6815 - val_acc: 0.0000e+00\n",
            "Epoch 34/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 88.8018 - acc: 0.0038 - val_loss: 2540.3211 - val_acc: 0.0000e+00\n",
            "Epoch 35/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 120.1431 - acc: 9.5238e-04 - val_loss: 2437.6209 - val_acc: 0.0000e+00\n",
            "Epoch 36/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 109.4877 - acc: 0.0019 - val_loss: 2159.3915 - val_acc: 0.0000e+00\n",
            "Epoch 37/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 100.0945 - acc: 0.0033 - val_loss: 2289.9006 - val_acc: 0.0000e+00\n",
            "Epoch 38/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 107.1205 - acc: 0.0019 - val_loss: 2649.5222 - val_acc: 0.0064\n",
            "Epoch 39/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 95.2192 - acc: 4.7619e-04 - val_loss: 2441.4032 - val_acc: 0.0000e+00\n",
            "Epoch 40/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 93.8933 - acc: 0.0029 - val_loss: 2397.4318 - val_acc: 0.0000e+00\n",
            "Epoch 41/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 108.7577 - acc: 9.5238e-04 - val_loss: 2400.5862 - val_acc: 0.0000e+00\n",
            "Epoch 42/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 88.1261 - acc: 0.0029 - val_loss: 2456.9057 - val_acc: 0.0000e+00\n",
            "Epoch 43/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 92.4196 - acc: 0.0029 - val_loss: 2472.0769 - val_acc: 0.0000e+00\n",
            "Epoch 44/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 116.9585 - acc: 0.0029 - val_loss: 2221.4739 - val_acc: 0.0000e+00\n",
            "Epoch 45/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 111.9966 - acc: 0.0019 - val_loss: 2323.6821 - val_acc: 0.0000e+00\n",
            "Epoch 46/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 133.8138 - acc: 9.5238e-04 - val_loss: 2007.1319 - val_acc: 0.0000e+00\n",
            "Epoch 47/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 110.8924 - acc: 4.7619e-04 - val_loss: 1975.6752 - val_acc: 0.0064\n",
            "Epoch 48/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 95.6222 - acc: 0.0024 - val_loss: 2118.2813 - val_acc: 0.0000e+00\n",
            "Epoch 49/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 96.2599 - acc: 0.0043 - val_loss: 2291.1696 - val_acc: 0.0000e+00\n",
            "Epoch 50/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 100.9949 - acc: 4.7619e-04 - val_loss: 2148.4898 - val_acc: 0.0000e+00\n",
            "Epoch 51/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 118.5618 - acc: 0.0014 - val_loss: 2000.1215 - val_acc: 0.0000e+00\n",
            "Epoch 52/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 95.5542 - acc: 9.5238e-04 - val_loss: 2016.7867 - val_acc: 0.0000e+00\n",
            "Epoch 53/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 97.3824 - acc: 0.0019 - val_loss: 2732.1851 - val_acc: 0.0000e+00\n",
            "Epoch 54/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 98.4690 - acc: 0.0024 - val_loss: 2314.5640 - val_acc: 0.0000e+00\n",
            "Epoch 55/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 92.2052 - acc: 0.0029 - val_loss: 2551.4354 - val_acc: 0.0000e+00\n",
            "Epoch 56/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 102.0041 - acc: 0.0024 - val_loss: 2570.9994 - val_acc: 0.0000e+00\n",
            "Epoch 57/400\n",
            "2100/2100 [==============================] - 0s 209us/step - loss: 92.7357 - acc: 0.0019 - val_loss: 3598.8362 - val_acc: 0.0000e+00\n",
            "Epoch 58/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 99.6892 - acc: 0.0014 - val_loss: 2914.5225 - val_acc: 0.0000e+00\n",
            "Epoch 59/400\n",
            "2100/2100 [==============================] - 0s 206us/step - loss: 84.5109 - acc: 0.0029 - val_loss: 2072.7830 - val_acc: 0.0000e+00\n",
            "Epoch 60/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 88.9042 - acc: 0.0024 - val_loss: 2203.8776 - val_acc: 0.0000e+00\n",
            "Epoch 61/400\n",
            "2100/2100 [==============================] - 0s 205us/step - loss: 102.9236 - acc: 0.0029 - val_loss: 2064.3377 - val_acc: 0.0000e+00\n",
            "Epoch 62/400\n",
            "2100/2100 [==============================] - 0s 209us/step - loss: 98.9124 - acc: 0.0014 - val_loss: 2482.2947 - val_acc: 0.0000e+00\n",
            "Epoch 63/400\n",
            "2100/2100 [==============================] - 0s 205us/step - loss: 99.3430 - acc: 0.0024 - val_loss: 2254.7266 - val_acc: 0.0000e+00\n",
            "Epoch 64/400\n",
            "2100/2100 [==============================] - 0s 206us/step - loss: 117.3446 - acc: 9.5238e-04 - val_loss: 2406.7409 - val_acc: 0.0000e+00\n",
            "Epoch 65/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 93.2241 - acc: 0.0014 - val_loss: 2219.0973 - val_acc: 0.0000e+00\n",
            "Epoch 66/400\n",
            "2100/2100 [==============================] - 0s 207us/step - loss: 127.2413 - acc: 9.5238e-04 - val_loss: 2739.8510 - val_acc: 0.0000e+00\n",
            "Epoch 67/400\n",
            "2100/2100 [==============================] - 0s 213us/step - loss: 108.9696 - acc: 0.0024 - val_loss: 1926.3959 - val_acc: 0.0000e+00\n",
            "Epoch 68/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 86.6950 - acc: 0.0014 - val_loss: 2701.0644 - val_acc: 0.0000e+00\n",
            "Epoch 69/400\n",
            "2100/2100 [==============================] - 0s 207us/step - loss: 84.9055 - acc: 4.7619e-04 - val_loss: 2238.7085 - val_acc: 0.0000e+00\n",
            "Epoch 70/400\n",
            "2100/2100 [==============================] - 0s 206us/step - loss: 85.0402 - acc: 0.0038 - val_loss: 2317.2271 - val_acc: 0.0000e+00\n",
            "Epoch 71/400\n",
            "2100/2100 [==============================] - 0s 206us/step - loss: 115.2963 - acc: 4.7619e-04 - val_loss: 2643.6246 - val_acc: 0.0000e+00\n",
            "Epoch 72/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 100.7579 - acc: 4.7619e-04 - val_loss: 2068.8780 - val_acc: 0.0000e+00\n",
            "Epoch 73/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 102.2507 - acc: 9.5238e-04 - val_loss: 2285.1019 - val_acc: 0.0000e+00\n",
            "Epoch 74/400\n",
            "2100/2100 [==============================] - 0s 208us/step - loss: 82.0812 - acc: 0.0024 - val_loss: 2213.3571 - val_acc: 0.0000e+00\n",
            "Epoch 75/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 93.2712 - acc: 4.7619e-04 - val_loss: 3127.9326 - val_acc: 0.0000e+00\n",
            "Epoch 76/400\n",
            "2100/2100 [==============================] - 0s 213us/step - loss: 101.2866 - acc: 0.0019 - val_loss: 2292.3916 - val_acc: 0.0000e+00\n",
            "Epoch 77/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 95.2541 - acc: 0.0024 - val_loss: 3117.0568 - val_acc: 0.0000e+00\n",
            "Epoch 78/400\n",
            "2100/2100 [==============================] - 0s 206us/step - loss: 86.2549 - acc: 0.0029 - val_loss: 2413.8551 - val_acc: 0.0000e+00\n",
            "Epoch 79/400\n",
            "2100/2100 [==============================] - 0s 206us/step - loss: 83.9556 - acc: 0.0014 - val_loss: 2148.3559 - val_acc: 0.0000e+00\n",
            "Epoch 80/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 87.8334 - acc: 0.0014 - val_loss: 2341.7811 - val_acc: 0.0000e+00\n",
            "Epoch 81/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 85.5529 - acc: 0.0024 - val_loss: 2583.5965 - val_acc: 0.0000e+00\n",
            "Epoch 82/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 87.9358 - acc: 0.0014 - val_loss: 2453.2484 - val_acc: 0.0000e+00\n",
            "Epoch 83/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 109.3832 - acc: 0.0029 - val_loss: 2705.9200 - val_acc: 0.0000e+00\n",
            "Epoch 84/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 96.4932 - acc: 0.0024 - val_loss: 2332.2836 - val_acc: 0.0000e+00\n",
            "Epoch 85/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 98.0853 - acc: 0.0019 - val_loss: 2980.8370 - val_acc: 0.0000e+00\n",
            "Epoch 86/400\n",
            "2100/2100 [==============================] - 0s 205us/step - loss: 129.5553 - acc: 0.0000e+00 - val_loss: 2269.5902 - val_acc: 0.0000e+00\n",
            "Epoch 87/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 99.0240 - acc: 0.0019 - val_loss: 2604.3782 - val_acc: 0.0000e+00\n",
            "Epoch 88/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 92.0677 - acc: 9.5238e-04 - val_loss: 2155.1512 - val_acc: 0.0000e+00\n",
            "Epoch 89/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 85.9732 - acc: 0.0019 - val_loss: 2232.2840 - val_acc: 0.0000e+00\n",
            "Epoch 90/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 86.4434 - acc: 0.0029 - val_loss: 2444.0830 - val_acc: 0.0000e+00\n",
            "Epoch 91/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 79.8705 - acc: 0.0029 - val_loss: 2683.6242 - val_acc: 0.0000e+00\n",
            "Epoch 92/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 81.0581 - acc: 9.5238e-04 - val_loss: 2299.2052 - val_acc: 0.0000e+00\n",
            "Epoch 93/400\n",
            "2100/2100 [==============================] - 0s 205us/step - loss: 83.9100 - acc: 0.0033 - val_loss: 2500.0306 - val_acc: 0.0000e+00\n",
            "Epoch 94/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 78.2063 - acc: 9.5238e-04 - val_loss: 2451.2783 - val_acc: 0.0000e+00\n",
            "Epoch 95/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 74.3266 - acc: 0.0029 - val_loss: 2307.2701 - val_acc: 0.0000e+00\n",
            "Epoch 96/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 75.5593 - acc: 0.0019 - val_loss: 2790.5456 - val_acc: 0.0000e+00\n",
            "Epoch 97/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 118.3756 - acc: 0.0029 - val_loss: 2554.8412 - val_acc: 0.0000e+00\n",
            "Epoch 98/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 86.8490 - acc: 0.0019 - val_loss: 2422.0397 - val_acc: 0.0000e+00\n",
            "Epoch 99/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 84.7805 - acc: 0.0019 - val_loss: 2300.9531 - val_acc: 0.0000e+00\n",
            "Epoch 100/400\n",
            "2100/2100 [==============================] - 0s 210us/step - loss: 82.1268 - acc: 0.0014 - val_loss: 2558.5672 - val_acc: 0.0000e+00\n",
            "Epoch 101/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 111.2345 - acc: 0.0024 - val_loss: 3276.9647 - val_acc: 0.0000e+00\n",
            "Epoch 102/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 111.3519 - acc: 9.5238e-04 - val_loss: 3002.2354 - val_acc: 0.0000e+00\n",
            "Epoch 103/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 95.0979 - acc: 0.0029 - val_loss: 2554.7432 - val_acc: 0.0000e+00\n",
            "Epoch 104/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 85.9431 - acc: 0.0024 - val_loss: 3264.8945 - val_acc: 0.0000e+00\n",
            "Epoch 105/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 90.7005 - acc: 4.7619e-04 - val_loss: 2460.9881 - val_acc: 0.0000e+00\n",
            "Epoch 106/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 81.1787 - acc: 0.0014 - val_loss: 2349.7870 - val_acc: 0.0000e+00\n",
            "Epoch 107/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 97.4093 - acc: 0.0024 - val_loss: 2494.3749 - val_acc: 0.0000e+00\n",
            "Epoch 108/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 82.9936 - acc: 0.0033 - val_loss: 2464.4738 - val_acc: 0.0000e+00\n",
            "Epoch 109/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 87.8276 - acc: 0.0014 - val_loss: 2701.9011 - val_acc: 0.0000e+00\n",
            "Epoch 110/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 98.2628 - acc: 0.0014 - val_loss: 2292.7144 - val_acc: 0.0000e+00\n",
            "Epoch 111/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 89.1870 - acc: 0.0014 - val_loss: 2282.6742 - val_acc: 0.0000e+00\n",
            "Epoch 112/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 81.7038 - acc: 0.0014 - val_loss: 2609.7367 - val_acc: 0.0000e+00\n",
            "Epoch 113/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 84.9912 - acc: 9.5238e-04 - val_loss: 2365.9470 - val_acc: 0.0000e+00\n",
            "Epoch 114/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 96.4139 - acc: 0.0019 - val_loss: 2164.5118 - val_acc: 0.0000e+00\n",
            "Epoch 115/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 89.5249 - acc: 9.5238e-04 - val_loss: 3013.7105 - val_acc: 0.0000e+00\n",
            "Epoch 116/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 125.5850 - acc: 0.0014 - val_loss: 3778.2691 - val_acc: 0.0000e+00\n",
            "Epoch 117/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 121.7819 - acc: 0.0024 - val_loss: 2426.8540 - val_acc: 0.0000e+00\n",
            "Epoch 118/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 116.8468 - acc: 9.5238e-04 - val_loss: 2157.4091 - val_acc: 0.0064\n",
            "Epoch 119/400\n",
            "2100/2100 [==============================] - 0s 191us/step - loss: 83.4945 - acc: 0.0019 - val_loss: 2162.4130 - val_acc: 0.0000e+00\n",
            "Epoch 120/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 87.7213 - acc: 4.7619e-04 - val_loss: 2468.0555 - val_acc: 0.0000e+00\n",
            "Epoch 121/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 73.9294 - acc: 0.0014 - val_loss: 2370.0683 - val_acc: 0.0000e+00\n",
            "Epoch 122/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 72.8639 - acc: 0.0033 - val_loss: 2672.8008 - val_acc: 0.0000e+00\n",
            "Epoch 123/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 73.8761 - acc: 9.5238e-04 - val_loss: 2535.7596 - val_acc: 0.0000e+00\n",
            "Epoch 124/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 71.2023 - acc: 0.0014 - val_loss: 2945.5461 - val_acc: 0.0000e+00\n",
            "Epoch 125/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 77.6869 - acc: 9.5238e-04 - val_loss: 2989.8188 - val_acc: 0.0000e+00\n",
            "Epoch 126/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 72.3432 - acc: 0.0024 - val_loss: 2671.0355 - val_acc: 0.0000e+00\n",
            "Epoch 127/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 70.7266 - acc: 0.0019 - val_loss: 2608.6735 - val_acc: 0.0000e+00\n",
            "Epoch 128/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 70.6825 - acc: 4.7619e-04 - val_loss: 2685.6325 - val_acc: 0.0000e+00\n",
            "Epoch 129/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 85.8128 - acc: 0.0014 - val_loss: 2759.8774 - val_acc: 0.0000e+00\n",
            "Epoch 130/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 84.8318 - acc: 0.0024 - val_loss: 2568.4359 - val_acc: 0.0000e+00\n",
            "Epoch 131/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 80.9974 - acc: 0.0019 - val_loss: 2321.4793 - val_acc: 0.0000e+00\n",
            "Epoch 132/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 75.7388 - acc: 4.7619e-04 - val_loss: 2383.5552 - val_acc: 0.0000e+00\n",
            "Epoch 133/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 78.3103 - acc: 0.0019 - val_loss: 2656.3442 - val_acc: 0.0000e+00\n",
            "Epoch 134/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 77.1662 - acc: 0.0024 - val_loss: 2707.8203 - val_acc: 0.0000e+00\n",
            "Epoch 135/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 70.1864 - acc: 0.0029 - val_loss: 3116.1006 - val_acc: 0.0000e+00\n",
            "Epoch 136/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 80.6740 - acc: 0.0014 - val_loss: 2779.1245 - val_acc: 0.0000e+00\n",
            "Epoch 137/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 83.0187 - acc: 9.5238e-04 - val_loss: 2499.7967 - val_acc: 0.0000e+00\n",
            "Epoch 138/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 85.0185 - acc: 0.0029 - val_loss: 2524.7489 - val_acc: 0.0000e+00\n",
            "Epoch 139/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 93.1226 - acc: 0.0024 - val_loss: 2822.5697 - val_acc: 0.0000e+00\n",
            "Epoch 140/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 106.6621 - acc: 9.5238e-04 - val_loss: 2883.7071 - val_acc: 0.0000e+00\n",
            "Epoch 141/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 96.1850 - acc: 0.0019 - val_loss: 2292.0132 - val_acc: 0.0000e+00\n",
            "Epoch 142/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 83.7094 - acc: 4.7619e-04 - val_loss: 2516.3146 - val_acc: 0.0000e+00\n",
            "Epoch 143/400\n",
            "2100/2100 [==============================] - 0s 189us/step - loss: 81.4818 - acc: 0.0019 - val_loss: 2427.6871 - val_acc: 0.0000e+00\n",
            "Epoch 144/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 70.7452 - acc: 9.5238e-04 - val_loss: 2439.3720 - val_acc: 0.0000e+00\n",
            "Epoch 145/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 67.0913 - acc: 9.5238e-04 - val_loss: 2625.5698 - val_acc: 0.0000e+00\n",
            "Epoch 146/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 69.5978 - acc: 0.0014 - val_loss: 2933.7739 - val_acc: 0.0064\n",
            "Epoch 147/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 67.1976 - acc: 0.0029 - val_loss: 3142.9022 - val_acc: 0.0000e+00\n",
            "Epoch 148/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 72.0006 - acc: 9.5238e-04 - val_loss: 2632.6619 - val_acc: 0.0000e+00\n",
            "Epoch 149/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 79.5392 - acc: 0.0014 - val_loss: 2783.6428 - val_acc: 0.0000e+00\n",
            "Epoch 150/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 69.9136 - acc: 0.0019 - val_loss: 2474.8368 - val_acc: 0.0000e+00\n",
            "Epoch 151/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 77.3535 - acc: 9.5238e-04 - val_loss: 2781.4932 - val_acc: 0.0000e+00\n",
            "Epoch 152/400\n",
            "2100/2100 [==============================] - 0s 204us/step - loss: 77.2710 - acc: 0.0029 - val_loss: 2823.9027 - val_acc: 0.0000e+00\n",
            "Epoch 153/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 85.1186 - acc: 0.0024 - val_loss: 2935.9471 - val_acc: 0.0000e+00\n",
            "Epoch 154/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 91.1417 - acc: 9.5238e-04 - val_loss: 3634.8839 - val_acc: 0.0000e+00\n",
            "Epoch 155/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 74.6995 - acc: 0.0014 - val_loss: 2805.5084 - val_acc: 0.0000e+00\n",
            "Epoch 156/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 78.9148 - acc: 0.0014 - val_loss: 2544.4105 - val_acc: 0.0000e+00\n",
            "Epoch 157/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 82.3468 - acc: 0.0014 - val_loss: 3360.0521 - val_acc: 0.0000e+00\n",
            "Epoch 158/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 96.4803 - acc: 9.5238e-04 - val_loss: 2754.3193 - val_acc: 0.0064\n",
            "Epoch 159/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 84.4311 - acc: 0.0019 - val_loss: 2633.9496 - val_acc: 0.0000e+00\n",
            "Epoch 160/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 105.5810 - acc: 9.5238e-04 - val_loss: 2588.1117 - val_acc: 0.0000e+00\n",
            "Epoch 161/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 77.6260 - acc: 0.0019 - val_loss: 3035.6919 - val_acc: 0.0000e+00\n",
            "Epoch 162/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 80.3339 - acc: 0.0014 - val_loss: 2552.9913 - val_acc: 0.0000e+00\n",
            "Epoch 163/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 71.1978 - acc: 0.0014 - val_loss: 3130.7139 - val_acc: 0.0000e+00\n",
            "Epoch 164/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 71.5100 - acc: 0.0024 - val_loss: 2637.4498 - val_acc: 0.0000e+00\n",
            "Epoch 165/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 92.2325 - acc: 0.0014 - val_loss: 3320.9153 - val_acc: 0.0000e+00\n",
            "Epoch 166/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 95.4551 - acc: 0.0019 - val_loss: 3686.2740 - val_acc: 0.0000e+00\n",
            "Epoch 167/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 134.4016 - acc: 4.7619e-04 - val_loss: 3082.9221 - val_acc: 0.0000e+00\n",
            "Epoch 168/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 95.2238 - acc: 0.0014 - val_loss: 2569.2637 - val_acc: 0.0000e+00\n",
            "Epoch 169/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 97.1219 - acc: 0.0024 - val_loss: 2260.1451 - val_acc: 0.0000e+00\n",
            "Epoch 170/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 83.5278 - acc: 0.0029 - val_loss: 2549.2578 - val_acc: 0.0000e+00\n",
            "Epoch 171/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 76.0477 - acc: 0.0014 - val_loss: 2618.4778 - val_acc: 0.0000e+00\n",
            "Epoch 172/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 74.9265 - acc: 0.0024 - val_loss: 2638.9480 - val_acc: 0.0000e+00\n",
            "Epoch 173/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 69.2869 - acc: 0.0019 - val_loss: 2751.2976 - val_acc: 0.0000e+00\n",
            "Epoch 174/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 65.7299 - acc: 0.0029 - val_loss: 2758.0535 - val_acc: 0.0000e+00\n",
            "Epoch 175/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 89.6867 - acc: 0.0014 - val_loss: 3796.8349 - val_acc: 0.0000e+00\n",
            "Epoch 176/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 87.9802 - acc: 0.0014 - val_loss: 2717.4288 - val_acc: 0.0000e+00\n",
            "Epoch 177/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 78.6806 - acc: 4.7619e-04 - val_loss: 2538.3451 - val_acc: 0.0000e+00\n",
            "Epoch 178/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 83.4830 - acc: 0.0019 - val_loss: 2693.4007 - val_acc: 0.0000e+00\n",
            "Epoch 179/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 82.5213 - acc: 0.0033 - val_loss: 3052.9261 - val_acc: 0.0000e+00\n",
            "Epoch 180/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 66.6764 - acc: 9.5238e-04 - val_loss: 3026.0521 - val_acc: 0.0000e+00\n",
            "Epoch 181/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 70.7115 - acc: 4.7619e-04 - val_loss: 2984.7116 - val_acc: 0.0000e+00\n",
            "Epoch 182/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 76.4109 - acc: 0.0024 - val_loss: 2918.8641 - val_acc: 0.0000e+00\n",
            "Epoch 183/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 81.0442 - acc: 4.7619e-04 - val_loss: 2761.2539 - val_acc: 0.0000e+00\n",
            "Epoch 184/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 75.5535 - acc: 0.0033 - val_loss: 3695.0761 - val_acc: 0.0000e+00\n",
            "Epoch 185/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 71.9579 - acc: 0.0033 - val_loss: 2726.1998 - val_acc: 0.0000e+00\n",
            "Epoch 186/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 75.4893 - acc: 0.0019 - val_loss: 3164.2760 - val_acc: 0.0000e+00\n",
            "Epoch 187/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 82.2512 - acc: 0.0014 - val_loss: 2860.2871 - val_acc: 0.0000e+00\n",
            "Epoch 188/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 70.4692 - acc: 0.0019 - val_loss: 2566.9537 - val_acc: 0.0000e+00\n",
            "Epoch 189/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 69.4313 - acc: 0.0024 - val_loss: 2572.3900 - val_acc: 0.0000e+00\n",
            "Epoch 190/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 66.8961 - acc: 0.0029 - val_loss: 2893.2284 - val_acc: 0.0000e+00\n",
            "Epoch 191/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 72.0080 - acc: 0.0043 - val_loss: 3095.5242 - val_acc: 0.0000e+00\n",
            "Epoch 192/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 95.9521 - acc: 0.0014 - val_loss: 3276.0764 - val_acc: 0.0000e+00\n",
            "Epoch 193/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 77.5008 - acc: 9.5238e-04 - val_loss: 2503.3825 - val_acc: 0.0000e+00\n",
            "Epoch 194/400\n",
            "2100/2100 [==============================] - 0s 205us/step - loss: 80.0781 - acc: 0.0024 - val_loss: 2749.7788 - val_acc: 0.0000e+00\n",
            "Epoch 195/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 78.4642 - acc: 0.0014 - val_loss: 2639.5644 - val_acc: 0.0000e+00\n",
            "Epoch 196/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 75.6150 - acc: 0.0014 - val_loss: 2750.9514 - val_acc: 0.0000e+00\n",
            "Epoch 197/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 83.1294 - acc: 0.0000e+00 - val_loss: 2864.2837 - val_acc: 0.0000e+00\n",
            "Epoch 198/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 74.8405 - acc: 0.0019 - val_loss: 2933.8098 - val_acc: 0.0000e+00\n",
            "Epoch 199/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 69.8815 - acc: 0.0024 - val_loss: 2761.8214 - val_acc: 0.0000e+00\n",
            "Epoch 200/400\n",
            "2100/2100 [==============================] - 0s 191us/step - loss: 72.6159 - acc: 0.0014 - val_loss: 2769.5888 - val_acc: 0.0000e+00\n",
            "Epoch 201/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 67.1852 - acc: 0.0024 - val_loss: 2944.2622 - val_acc: 0.0000e+00\n",
            "Epoch 202/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 63.0030 - acc: 0.0019 - val_loss: 3113.0231 - val_acc: 0.0000e+00\n",
            "Epoch 203/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 77.2172 - acc: 4.7619e-04 - val_loss: 2918.2634 - val_acc: 0.0000e+00\n",
            "Epoch 204/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 73.3035 - acc: 0.0024 - val_loss: 2648.6403 - val_acc: 0.0000e+00\n",
            "Epoch 205/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 70.1843 - acc: 9.5238e-04 - val_loss: 2923.6353 - val_acc: 0.0000e+00\n",
            "Epoch 206/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 82.6267 - acc: 9.5238e-04 - val_loss: 3412.0976 - val_acc: 0.0000e+00\n",
            "Epoch 207/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 70.1045 - acc: 0.0019 - val_loss: 3145.3328 - val_acc: 0.0000e+00\n",
            "Epoch 208/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 92.8884 - acc: 0.0014 - val_loss: 2769.9438 - val_acc: 0.0000e+00\n",
            "Epoch 209/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 82.9278 - acc: 9.5238e-04 - val_loss: 2670.0387 - val_acc: 0.0000e+00\n",
            "Epoch 210/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 69.8700 - acc: 0.0038 - val_loss: 2634.2551 - val_acc: 0.0000e+00\n",
            "Epoch 211/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 97.5490 - acc: 0.0014 - val_loss: 2799.3875 - val_acc: 0.0000e+00\n",
            "Epoch 212/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 77.5366 - acc: 0.0019 - val_loss: 2646.7288 - val_acc: 0.0000e+00\n",
            "Epoch 213/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 79.1804 - acc: 0.0019 - val_loss: 2748.3281 - val_acc: 0.0000e+00\n",
            "Epoch 214/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 75.3112 - acc: 9.5238e-04 - val_loss: 2834.1276 - val_acc: 0.0000e+00\n",
            "Epoch 215/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 75.8811 - acc: 4.7619e-04 - val_loss: 2803.1349 - val_acc: 0.0000e+00\n",
            "Epoch 216/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 74.3361 - acc: 9.5238e-04 - val_loss: 2717.1449 - val_acc: 0.0000e+00\n",
            "Epoch 217/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 69.5789 - acc: 0.0033 - val_loss: 2718.3348 - val_acc: 0.0000e+00\n",
            "Epoch 218/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 70.5744 - acc: 9.5238e-04 - val_loss: 2876.5901 - val_acc: 0.0000e+00\n",
            "Epoch 219/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 69.2075 - acc: 9.5238e-04 - val_loss: 3172.9845 - val_acc: 0.0000e+00\n",
            "Epoch 220/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 88.4454 - acc: 0.0024 - val_loss: 3016.5746 - val_acc: 0.0000e+00\n",
            "Epoch 221/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 73.8725 - acc: 0.0014 - val_loss: 2830.7955 - val_acc: 0.0000e+00\n",
            "Epoch 222/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 70.7351 - acc: 0.0024 - val_loss: 3111.4495 - val_acc: 0.0000e+00\n",
            "Epoch 223/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 72.9937 - acc: 4.7619e-04 - val_loss: 3096.4142 - val_acc: 0.0000e+00\n",
            "Epoch 224/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 66.3863 - acc: 0.0019 - val_loss: 2852.4338 - val_acc: 0.0064\n",
            "Epoch 225/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 80.6246 - acc: 0.0014 - val_loss: 2772.2702 - val_acc: 0.0000e+00\n",
            "Epoch 226/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 78.2613 - acc: 9.5238e-04 - val_loss: 3188.3519 - val_acc: 0.0000e+00\n",
            "Epoch 227/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 80.4562 - acc: 9.5238e-04 - val_loss: 3108.5062 - val_acc: 0.0000e+00\n",
            "Epoch 228/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 81.9966 - acc: 0.0024 - val_loss: 2947.9905 - val_acc: 0.0000e+00\n",
            "Epoch 229/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 68.7604 - acc: 0.0019 - val_loss: 2830.3486 - val_acc: 0.0000e+00\n",
            "Epoch 230/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 66.4070 - acc: 0.0029 - val_loss: 3151.9808 - val_acc: 0.0000e+00\n",
            "Epoch 231/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 71.6041 - acc: 0.0019 - val_loss: 2940.3962 - val_acc: 0.0000e+00\n",
            "Epoch 232/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 64.9507 - acc: 0.0024 - val_loss: 2992.4963 - val_acc: 0.0000e+00\n",
            "Epoch 233/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 64.2164 - acc: 0.0014 - val_loss: 3073.2804 - val_acc: 0.0000e+00\n",
            "Epoch 234/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 71.4964 - acc: 0.0038 - val_loss: 2912.4224 - val_acc: 0.0000e+00\n",
            "Epoch 235/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 84.5545 - acc: 0.0014 - val_loss: 3005.0754 - val_acc: 0.0000e+00\n",
            "Epoch 236/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 73.3993 - acc: 9.5238e-04 - val_loss: 2656.6292 - val_acc: 0.0000e+00\n",
            "Epoch 237/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 90.4544 - acc: 0.0029 - val_loss: 2904.6952 - val_acc: 0.0000e+00\n",
            "Epoch 238/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 78.6354 - acc: 0.0024 - val_loss: 2533.8522 - val_acc: 0.0000e+00\n",
            "Epoch 239/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 66.9214 - acc: 0.0014 - val_loss: 3072.6607 - val_acc: 0.0000e+00\n",
            "Epoch 240/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 65.3868 - acc: 0.0019 - val_loss: 3109.7918 - val_acc: 0.0000e+00\n",
            "Epoch 241/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 78.0270 - acc: 0.0029 - val_loss: 3259.9686 - val_acc: 0.0000e+00\n",
            "Epoch 242/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 68.2826 - acc: 0.0024 - val_loss: 3100.4630 - val_acc: 0.0000e+00\n",
            "Epoch 243/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 71.2806 - acc: 0.0024 - val_loss: 2868.0158 - val_acc: 0.0000e+00\n",
            "Epoch 244/400\n",
            "2100/2100 [==============================] - 0s 204us/step - loss: 72.4900 - acc: 0.0014 - val_loss: 2676.8384 - val_acc: 0.0000e+00\n",
            "Epoch 245/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 64.4231 - acc: 0.0029 - val_loss: 2898.3848 - val_acc: 0.0000e+00\n",
            "Epoch 246/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 66.3055 - acc: 0.0019 - val_loss: 2914.2024 - val_acc: 0.0000e+00\n",
            "Epoch 247/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 72.1641 - acc: 4.7619e-04 - val_loss: 3107.3361 - val_acc: 0.0000e+00\n",
            "Epoch 248/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 67.0398 - acc: 0.0029 - val_loss: 2808.9785 - val_acc: 0.0000e+00\n",
            "Epoch 249/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 69.5304 - acc: 0.0014 - val_loss: 2960.4213 - val_acc: 0.0000e+00\n",
            "Epoch 250/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 79.4521 - acc: 0.0024 - val_loss: 2941.3322 - val_acc: 0.0000e+00\n",
            "Epoch 251/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 77.5676 - acc: 0.0014 - val_loss: 2996.9446 - val_acc: 0.0000e+00\n",
            "Epoch 252/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 73.5712 - acc: 0.0019 - val_loss: 3259.1763 - val_acc: 0.0000e+00\n",
            "Epoch 253/400\n",
            "2100/2100 [==============================] - 0s 204us/step - loss: 107.2486 - acc: 9.5238e-04 - val_loss: 2546.5578 - val_acc: 0.0000e+00\n",
            "Epoch 254/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 76.7281 - acc: 0.0033 - val_loss: 2607.8908 - val_acc: 0.0000e+00\n",
            "Epoch 255/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 66.8177 - acc: 0.0024 - val_loss: 2816.8979 - val_acc: 0.0000e+00\n",
            "Epoch 256/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 64.5171 - acc: 0.0033 - val_loss: 2911.7562 - val_acc: 0.0000e+00\n",
            "Epoch 257/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 71.6208 - acc: 0.0024 - val_loss: 2949.2360 - val_acc: 0.0000e+00\n",
            "Epoch 258/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 72.9807 - acc: 0.0014 - val_loss: 2929.3921 - val_acc: 0.0000e+00\n",
            "Epoch 259/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 107.1332 - acc: 4.7619e-04 - val_loss: 3111.6270 - val_acc: 0.0000e+00\n",
            "Epoch 260/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 77.8587 - acc: 9.5238e-04 - val_loss: 2559.4451 - val_acc: 0.0000e+00\n",
            "Epoch 261/400\n",
            "2100/2100 [==============================] - 0s 208us/step - loss: 74.7760 - acc: 0.0029 - val_loss: 2918.1676 - val_acc: 0.0000e+00\n",
            "Epoch 262/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 69.0692 - acc: 0.0019 - val_loss: 2993.6943 - val_acc: 0.0000e+00\n",
            "Epoch 263/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 80.3015 - acc: 0.0019 - val_loss: 2892.8819 - val_acc: 0.0000e+00\n",
            "Epoch 264/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 79.9268 - acc: 0.0024 - val_loss: 2785.6902 - val_acc: 0.0000e+00\n",
            "Epoch 265/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 68.2008 - acc: 0.0014 - val_loss: 2839.6073 - val_acc: 0.0000e+00\n",
            "Epoch 266/400\n",
            "2100/2100 [==============================] - 0s 205us/step - loss: 69.6060 - acc: 0.0019 - val_loss: 2956.8717 - val_acc: 0.0000e+00\n",
            "Epoch 267/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 69.0483 - acc: 0.0014 - val_loss: 3310.3485 - val_acc: 0.0000e+00\n",
            "Epoch 268/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 78.3295 - acc: 0.0019 - val_loss: 3156.1729 - val_acc: 0.0000e+00\n",
            "Epoch 269/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 67.3221 - acc: 0.0019 - val_loss: 3011.1563 - val_acc: 0.0000e+00\n",
            "Epoch 270/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 69.2762 - acc: 0.0019 - val_loss: 3312.4259 - val_acc: 0.0000e+00\n",
            "Epoch 271/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 62.9322 - acc: 0.0033 - val_loss: 3411.8890 - val_acc: 0.0000e+00\n",
            "Epoch 272/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 72.6821 - acc: 0.0019 - val_loss: 2857.7782 - val_acc: 0.0000e+00\n",
            "Epoch 273/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 68.8469 - acc: 9.5238e-04 - val_loss: 3184.0440 - val_acc: 0.0064\n",
            "Epoch 274/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 70.0047 - acc: 0.0019 - val_loss: 2925.9025 - val_acc: 0.0000e+00\n",
            "Epoch 275/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 73.5849 - acc: 0.0024 - val_loss: 3011.9419 - val_acc: 0.0000e+00\n",
            "Epoch 276/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 74.0106 - acc: 0.0014 - val_loss: 2849.2860 - val_acc: 0.0000e+00\n",
            "Epoch 277/400\n",
            "2100/2100 [==============================] - 0s 191us/step - loss: 76.2219 - acc: 0.0014 - val_loss: 2633.9917 - val_acc: 0.0000e+00\n",
            "Epoch 278/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 75.7327 - acc: 0.0019 - val_loss: 3068.5252 - val_acc: 0.0000e+00\n",
            "Epoch 279/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 82.8556 - acc: 0.0019 - val_loss: 2734.3979 - val_acc: 0.0000e+00\n",
            "Epoch 280/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 70.5554 - acc: 0.0033 - val_loss: 2716.5847 - val_acc: 0.0000e+00\n",
            "Epoch 281/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 66.5977 - acc: 9.5238e-04 - val_loss: 2870.8797 - val_acc: 0.0000e+00\n",
            "Epoch 282/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 66.9070 - acc: 0.0014 - val_loss: 2816.4311 - val_acc: 0.0000e+00\n",
            "Epoch 283/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 74.0288 - acc: 0.0014 - val_loss: 2821.0199 - val_acc: 0.0000e+00\n",
            "Epoch 284/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 74.9620 - acc: 4.7619e-04 - val_loss: 2958.5028 - val_acc: 0.0000e+00\n",
            "Epoch 285/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 87.7346 - acc: 0.0024 - val_loss: 2725.1073 - val_acc: 0.0000e+00\n",
            "Epoch 286/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 71.8593 - acc: 9.5238e-04 - val_loss: 2876.3512 - val_acc: 0.0000e+00\n",
            "Epoch 287/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 69.7914 - acc: 9.5238e-04 - val_loss: 2789.4811 - val_acc: 0.0000e+00\n",
            "Epoch 288/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 110.3377 - acc: 4.7619e-04 - val_loss: 2882.7624 - val_acc: 0.0000e+00\n",
            "Epoch 289/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 75.9785 - acc: 0.0043 - val_loss: 2494.3811 - val_acc: 0.0000e+00\n",
            "Epoch 290/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 71.4239 - acc: 0.0014 - val_loss: 2965.5026 - val_acc: 0.0000e+00\n",
            "Epoch 291/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 66.3450 - acc: 9.5238e-04 - val_loss: 3081.3088 - val_acc: 0.0000e+00\n",
            "Epoch 292/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 75.3409 - acc: 9.5238e-04 - val_loss: 2899.6230 - val_acc: 0.0000e+00\n",
            "Epoch 293/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 71.9384 - acc: 9.5238e-04 - val_loss: 2927.2418 - val_acc: 0.0000e+00\n",
            "Epoch 294/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 64.9043 - acc: 0.0014 - val_loss: 2808.9041 - val_acc: 0.0000e+00\n",
            "Epoch 295/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 68.7487 - acc: 0.0014 - val_loss: 3032.1168 - val_acc: 0.0000e+00\n",
            "Epoch 296/400\n",
            "2100/2100 [==============================] - 0s 191us/step - loss: 62.3490 - acc: 9.5238e-04 - val_loss: 3167.0013 - val_acc: 0.0000e+00\n",
            "Epoch 297/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 65.9654 - acc: 0.0029 - val_loss: 3040.2109 - val_acc: 0.0000e+00\n",
            "Epoch 298/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 70.0610 - acc: 9.5238e-04 - val_loss: 2905.7384 - val_acc: 0.0000e+00\n",
            "Epoch 299/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 68.0930 - acc: 0.0014 - val_loss: 4176.9894 - val_acc: 0.0000e+00\n",
            "Epoch 300/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 71.5188 - acc: 0.0048 - val_loss: 2849.8605 - val_acc: 0.0000e+00\n",
            "Epoch 301/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 86.8013 - acc: 0.0024 - val_loss: 2798.2857 - val_acc: 0.0000e+00\n",
            "Epoch 302/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 69.5027 - acc: 0.0014 - val_loss: 3178.9146 - val_acc: 0.0000e+00\n",
            "Epoch 303/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 100.3824 - acc: 9.5238e-04 - val_loss: 2768.6476 - val_acc: 0.0000e+00\n",
            "Epoch 304/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 84.9145 - acc: 0.0029 - val_loss: 2563.5916 - val_acc: 0.0000e+00\n",
            "Epoch 305/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 69.0967 - acc: 0.0014 - val_loss: 2763.4097 - val_acc: 0.0000e+00\n",
            "Epoch 306/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 62.3254 - acc: 0.0029 - val_loss: 2992.0857 - val_acc: 0.0000e+00\n",
            "Epoch 307/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 62.0226 - acc: 0.0029 - val_loss: 2857.4995 - val_acc: 0.0000e+00\n",
            "Epoch 308/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 82.8652 - acc: 0.0019 - val_loss: 3050.3670 - val_acc: 0.0000e+00\n",
            "Epoch 309/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 75.7168 - acc: 0.0019 - val_loss: 2809.0165 - val_acc: 0.0000e+00\n",
            "Epoch 310/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 63.5938 - acc: 9.5238e-04 - val_loss: 2838.4738 - val_acc: 0.0000e+00\n",
            "Epoch 311/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 82.2097 - acc: 0.0014 - val_loss: 3367.4034 - val_acc: 0.0000e+00\n",
            "Epoch 312/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 73.6972 - acc: 0.0014 - val_loss: 2729.8729 - val_acc: 0.0000e+00\n",
            "Epoch 313/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 64.6243 - acc: 9.5238e-04 - val_loss: 2980.5179 - val_acc: 0.0064\n",
            "Epoch 314/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 63.3832 - acc: 0.0043 - val_loss: 3157.8221 - val_acc: 0.0000e+00\n",
            "Epoch 315/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 80.2912 - acc: 0.0019 - val_loss: 3007.0245 - val_acc: 0.0064\n",
            "Epoch 316/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 69.2282 - acc: 0.0019 - val_loss: 2709.3895 - val_acc: 0.0000e+00\n",
            "Epoch 317/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 64.7288 - acc: 0.0033 - val_loss: 3276.1169 - val_acc: 0.0000e+00\n",
            "Epoch 318/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 73.3023 - acc: 0.0033 - val_loss: 2695.6919 - val_acc: 0.0000e+00\n",
            "Epoch 319/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 72.7125 - acc: 0.0014 - val_loss: 2684.0103 - val_acc: 0.0000e+00\n",
            "Epoch 320/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 63.2224 - acc: 0.0019 - val_loss: 2929.1300 - val_acc: 0.0000e+00\n",
            "Epoch 321/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 62.5846 - acc: 0.0019 - val_loss: 2690.0932 - val_acc: 0.0000e+00\n",
            "Epoch 322/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 66.5259 - acc: 0.0014 - val_loss: 3611.0896 - val_acc: 0.0000e+00\n",
            "Epoch 323/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 77.5754 - acc: 0.0019 - val_loss: 3291.9431 - val_acc: 0.0000e+00\n",
            "Epoch 324/400\n",
            "2100/2100 [==============================] - 0s 191us/step - loss: 88.4016 - acc: 0.0019 - val_loss: 3471.6727 - val_acc: 0.0000e+00\n",
            "Epoch 325/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 79.2365 - acc: 0.0024 - val_loss: 2839.4052 - val_acc: 0.0000e+00\n",
            "Epoch 326/400\n",
            "2100/2100 [==============================] - 0s 202us/step - loss: 86.1934 - acc: 9.5238e-04 - val_loss: 3650.1841 - val_acc: 0.0000e+00\n",
            "Epoch 327/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 79.3158 - acc: 0.0029 - val_loss: 2966.6114 - val_acc: 0.0000e+00\n",
            "Epoch 328/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 71.0134 - acc: 0.0014 - val_loss: 2754.2486 - val_acc: 0.0000e+00\n",
            "Epoch 329/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 69.6578 - acc: 0.0029 - val_loss: 3348.9425 - val_acc: 0.0000e+00\n",
            "Epoch 330/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 66.9329 - acc: 9.5238e-04 - val_loss: 2839.9788 - val_acc: 0.0000e+00\n",
            "Epoch 331/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 69.9453 - acc: 0.0014 - val_loss: 2963.9564 - val_acc: 0.0000e+00\n",
            "Epoch 332/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 65.2129 - acc: 0.0014 - val_loss: 3209.5286 - val_acc: 0.0000e+00\n",
            "Epoch 333/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 64.6464 - acc: 0.0033 - val_loss: 2830.8775 - val_acc: 0.0000e+00\n",
            "Epoch 334/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 67.5072 - acc: 0.0024 - val_loss: 2769.5682 - val_acc: 0.0000e+00\n",
            "Epoch 335/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 81.0295 - acc: 0.0024 - val_loss: 2957.1333 - val_acc: 0.0000e+00\n",
            "Epoch 336/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 67.9019 - acc: 0.0019 - val_loss: 3874.0331 - val_acc: 0.0000e+00\n",
            "Epoch 337/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 77.0050 - acc: 0.0019 - val_loss: 2807.9315 - val_acc: 0.0000e+00\n",
            "Epoch 338/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 84.5173 - acc: 4.7619e-04 - val_loss: 2704.3553 - val_acc: 0.0000e+00\n",
            "Epoch 339/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 66.2816 - acc: 0.0019 - val_loss: 2920.2157 - val_acc: 0.0000e+00\n",
            "Epoch 340/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 68.0424 - acc: 9.5238e-04 - val_loss: 2969.0644 - val_acc: 0.0000e+00\n",
            "Epoch 341/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 68.7022 - acc: 9.5238e-04 - val_loss: 2834.6311 - val_acc: 0.0000e+00\n",
            "Epoch 342/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 65.4376 - acc: 0.0019 - val_loss: 2894.4813 - val_acc: 0.0000e+00\n",
            "Epoch 343/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 71.5312 - acc: 0.0014 - val_loss: 3156.0579 - val_acc: 0.0000e+00\n",
            "Epoch 344/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 68.7414 - acc: 0.0014 - val_loss: 2692.6594 - val_acc: 0.0000e+00\n",
            "Epoch 345/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 67.6194 - acc: 9.5238e-04 - val_loss: 2785.5286 - val_acc: 0.0000e+00\n",
            "Epoch 346/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 88.1354 - acc: 0.0014 - val_loss: 2932.5901 - val_acc: 0.0000e+00\n",
            "Epoch 347/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 67.3791 - acc: 4.7619e-04 - val_loss: 2789.1814 - val_acc: 0.0000e+00\n",
            "Epoch 348/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 72.8836 - acc: 0.0019 - val_loss: 2973.8959 - val_acc: 0.0000e+00\n",
            "Epoch 349/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 64.3955 - acc: 0.0019 - val_loss: 2741.6526 - val_acc: 0.0000e+00\n",
            "Epoch 350/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 62.8130 - acc: 0.0029 - val_loss: 2978.8895 - val_acc: 0.0000e+00\n",
            "Epoch 351/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 62.0363 - acc: 0.0024 - val_loss: 2785.1570 - val_acc: 0.0000e+00\n",
            "Epoch 352/400\n",
            "2100/2100 [==============================] - 0s 203us/step - loss: 73.0239 - acc: 0.0033 - val_loss: 3555.4584 - val_acc: 0.0000e+00\n",
            "Epoch 353/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 72.2799 - acc: 4.7619e-04 - val_loss: 3211.4481 - val_acc: 0.0000e+00\n",
            "Epoch 354/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 80.5838 - acc: 0.0019 - val_loss: 3698.6108 - val_acc: 0.0000e+00\n",
            "Epoch 355/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 92.3386 - acc: 0.0024 - val_loss: 2808.8726 - val_acc: 0.0000e+00\n",
            "Epoch 356/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 88.2756 - acc: 0.0019 - val_loss: 2711.5361 - val_acc: 0.0000e+00\n",
            "Epoch 357/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 67.2757 - acc: 9.5238e-04 - val_loss: 3001.9267 - val_acc: 0.0000e+00\n",
            "Epoch 358/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 62.0235 - acc: 0.0024 - val_loss: 3092.3411 - val_acc: 0.0000e+00\n",
            "Epoch 359/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 65.5608 - acc: 0.0043 - val_loss: 3150.3053 - val_acc: 0.0000e+00\n",
            "Epoch 360/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 64.3771 - acc: 9.5238e-04 - val_loss: 2838.6439 - val_acc: 0.0000e+00\n",
            "Epoch 361/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 68.1728 - acc: 0.0024 - val_loss: 2997.2632 - val_acc: 0.0000e+00\n",
            "Epoch 362/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 77.1754 - acc: 0.0024 - val_loss: 2732.0391 - val_acc: 0.0000e+00\n",
            "Epoch 363/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 72.9473 - acc: 4.7619e-04 - val_loss: 2739.4321 - val_acc: 0.0000e+00\n",
            "Epoch 364/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 68.3843 - acc: 0.0019 - val_loss: 2832.5168 - val_acc: 0.0000e+00\n",
            "Epoch 365/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 66.9147 - acc: 0.0019 - val_loss: 3149.2871 - val_acc: 0.0000e+00\n",
            "Epoch 366/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 67.9910 - acc: 0.0014 - val_loss: 2912.2876 - val_acc: 0.0000e+00\n",
            "Epoch 367/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 76.8072 - acc: 0.0019 - val_loss: 2927.2812 - val_acc: 0.0000e+00\n",
            "Epoch 368/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 72.0955 - acc: 9.5238e-04 - val_loss: 2818.5646 - val_acc: 0.0000e+00\n",
            "Epoch 369/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 73.0643 - acc: 9.5238e-04 - val_loss: 2600.1598 - val_acc: 0.0000e+00\n",
            "Epoch 370/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 68.7307 - acc: 0.0038 - val_loss: 2648.3847 - val_acc: 0.0000e+00\n",
            "Epoch 371/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 61.3227 - acc: 0.0019 - val_loss: 2762.7990 - val_acc: 0.0000e+00\n",
            "Epoch 372/400\n",
            "2100/2100 [==============================] - 0s 201us/step - loss: 63.4792 - acc: 0.0019 - val_loss: 3789.6673 - val_acc: 0.0000e+00\n",
            "Epoch 373/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 70.5360 - acc: 0.0000e+00 - val_loss: 2720.6420 - val_acc: 0.0000e+00\n",
            "Epoch 374/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 70.8781 - acc: 0.0014 - val_loss: 2779.4099 - val_acc: 0.0000e+00\n",
            "Epoch 375/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 73.9985 - acc: 0.0014 - val_loss: 2764.1558 - val_acc: 0.0000e+00\n",
            "Epoch 376/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 74.6997 - acc: 0.0019 - val_loss: 3605.9913 - val_acc: 0.0000e+00\n",
            "Epoch 377/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 66.0722 - acc: 0.0019 - val_loss: 2853.7398 - val_acc: 0.0000e+00\n",
            "Epoch 378/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 67.1152 - acc: 0.0014 - val_loss: 3161.0130 - val_acc: 0.0000e+00\n",
            "Epoch 379/400\n",
            "2100/2100 [==============================] - 0s 205us/step - loss: 71.1451 - acc: 9.5238e-04 - val_loss: 3130.3426 - val_acc: 0.0000e+00\n",
            "Epoch 380/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 70.2514 - acc: 0.0033 - val_loss: 2680.5708 - val_acc: 0.0000e+00\n",
            "Epoch 381/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 78.0377 - acc: 0.0019 - val_loss: 2777.0612 - val_acc: 0.0000e+00\n",
            "Epoch 382/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 71.0558 - acc: 9.5238e-04 - val_loss: 2710.4527 - val_acc: 0.0000e+00\n",
            "Epoch 383/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 61.4551 - acc: 0.0024 - val_loss: 2854.5087 - val_acc: 0.0000e+00\n",
            "Epoch 384/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 70.6361 - acc: 0.0019 - val_loss: 2895.0349 - val_acc: 0.0000e+00\n",
            "Epoch 385/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 74.7897 - acc: 0.0014 - val_loss: 2821.0557 - val_acc: 0.0000e+00\n",
            "Epoch 386/400\n",
            "2100/2100 [==============================] - 0s 206us/step - loss: 72.3131 - acc: 0.0019 - val_loss: 2809.9495 - val_acc: 0.0000e+00\n",
            "Epoch 387/400\n",
            "2100/2100 [==============================] - 0s 193us/step - loss: 67.9426 - acc: 0.0014 - val_loss: 3230.0677 - val_acc: 0.0000e+00\n",
            "Epoch 388/400\n",
            "2100/2100 [==============================] - 0s 196us/step - loss: 73.1690 - acc: 0.0019 - val_loss: 3414.0537 - val_acc: 0.0000e+00\n",
            "Epoch 389/400\n",
            "2100/2100 [==============================] - 0s 198us/step - loss: 71.1061 - acc: 0.0019 - val_loss: 3018.1244 - val_acc: 0.0000e+00\n",
            "Epoch 390/400\n",
            "2100/2100 [==============================] - 0s 194us/step - loss: 69.0468 - acc: 9.5238e-04 - val_loss: 3113.5476 - val_acc: 0.0000e+00\n",
            "Epoch 391/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 73.2045 - acc: 9.5238e-04 - val_loss: 2831.1478 - val_acc: 0.0000e+00\n",
            "Epoch 392/400\n",
            "2100/2100 [==============================] - 0s 197us/step - loss: 65.2417 - acc: 0.0024 - val_loss: 2898.5166 - val_acc: 0.0000e+00\n",
            "Epoch 393/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 65.8655 - acc: 9.5238e-04 - val_loss: 3029.7869 - val_acc: 0.0000e+00\n",
            "Epoch 394/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 63.6503 - acc: 0.0014 - val_loss: 3109.3966 - val_acc: 0.0000e+00\n",
            "Epoch 395/400\n",
            "2100/2100 [==============================] - 0s 192us/step - loss: 69.2097 - acc: 0.0043 - val_loss: 2967.1233 - val_acc: 0.0000e+00\n",
            "Epoch 396/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 70.9111 - acc: 0.0019 - val_loss: 3382.1836 - val_acc: 0.0000e+00\n",
            "Epoch 397/400\n",
            "2100/2100 [==============================] - 0s 195us/step - loss: 77.2524 - acc: 0.0024 - val_loss: 2988.6400 - val_acc: 0.0000e+00\n",
            "Epoch 398/400\n",
            "2100/2100 [==============================] - 0s 191us/step - loss: 62.9797 - acc: 0.0024 - val_loss: 2790.2058 - val_acc: 0.0000e+00\n",
            "Epoch 399/400\n",
            "2100/2100 [==============================] - 0s 199us/step - loss: 59.2518 - acc: 0.0019 - val_loss: 2863.1020 - val_acc: 0.0000e+00\n",
            "Epoch 400/400\n",
            "2100/2100 [==============================] - 0s 200us/step - loss: 67.1472 - acc: 0.0024 - val_loss: 3383.6247 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffa6e3b3320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    }
  ]
}