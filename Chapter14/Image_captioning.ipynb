{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image captioning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tFyC689Yr9U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The recommended datasets for this exercise can be dowloaded from here:\n",
        "https://ai.googleblog.com/2018/09/conceptual-captions-new-dataset-and.html\n",
        "http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip\n"
      ]
    },
    {
      "metadata": {
        "id": "wZdVpyiHXdqW",
        "colab_type": "code",
        "outputId": "c4d2c929-76ce-4d35-e7b0-ee5399c8b776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector, merge, Activation, Flatten\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FwVGJgjMAWN-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token = '...'  # Path to captions file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TB1YgZ-fAcx9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "captions = open(token, 'r').read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DYlnRbWDAe_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d = {}\n",
        "for i, row in enumerate(captions):\n",
        "    row = row.split('\\t')\n",
        "    row[0] = row[0][:len(row[0])-2]\n",
        "    if row[0] in d:\n",
        "        d[row[0]].append(row[1])\n",
        "    else:\n",
        "        d[row[0]] = [row[1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GcGLlj_nAj6t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_images = list(d.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3B2I68wpgx1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WFCoc_YijuIm",
        "colab_type": "code",
        "outputId": "40d5c472-3907-41e9-8908-23ae035a390e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "vgg16=VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_PQuBiMkjFqP",
        "colab_type": "code",
        "outputId": "8734cc97-00a5-4999-c547-e4edeaa12b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        }
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "x = []\n",
        "y = []\n",
        "x2 = []\n",
        "tot_images = ''\n",
        "for i in range(len(d.keys())):\n",
        "#for i in range(1000):\n",
        "  if(i%100)==0:\n",
        "    print(i)\n",
        "  for j in range(len(d[total_images[i]])):\n",
        "    img_path = '...'   # Path to images\n",
        "    img = cv2.imread(img_path)\n",
        "    try:\n",
        "      img2 = cv2.resize(img, (224, 224))/255\n",
        "      img3 = vgg16.predict(img2.reshape(1,224,224,3))\n",
        "      #x.append(img)\n",
        "      x2.append(img3)\n",
        "      y.append(d[total_images[i]][j])\n",
        "      tot_images = tot_images + ' '+total_images[i]\n",
        "    except:\n",
        "      print(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cn8ksj0zvV8e",
        "colab_type": "code",
        "outputId": "ceb68d11-da13-4acb-c9f3-f4236e515c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x2 = np.array(x2)\n",
        "x2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40455, 1, 7, 7, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "tyGTtrSyk4g8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x2 = x2.reshape(x2.shape[0],7,7,512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjKAdsr6DB2m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_path2 = tot_images.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUCvRi_8g2lb",
        "colab_type": "code",
        "outputId": "d7fb0ba8-d809-4d6b-c09e-2b1390d8a010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop = nltk.corpus.stopwords.words('english')\n",
        "import re\n",
        "\n",
        "def preprocess(text):\n",
        " text=text.lower()\n",
        " text=re.sub('[^0-9a-zA-Z]+',' ',text)\n",
        " words = text.split()\n",
        " #words2=[w for w in words if (w not in stop)]\n",
        " words2 = words\n",
        " #words3=[ps.stem(w) for w in words]\n",
        " words4=' '.join(words2)\n",
        " return(words4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nY5iQoC01kL9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "caps = []\n",
        "for key, val in d.items():\n",
        "  if(key in img_path2):\n",
        "    for i in val:\n",
        "      i = preprocess(i)\n",
        "      caps.append('<start> ' + i + ' <end>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sar3CG-zTo-m",
        "colab_type": "code",
        "outputId": "a56bd317-0807-4781-b07f-6b56b236bccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(caps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "wECYSobXriJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word = ['child','girl']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ERxuMUD7qz4U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "caps2 = []\n",
        "x3 = []\n",
        "img_path3 = []\n",
        "for i in range(len(caps)):\n",
        "  if (('girl') in caps[i]):\n",
        "    caps2.append(caps[i])\n",
        "    x3.append(x2[i])\n",
        "    img_path3.append(img_path2[i])\n",
        "  elif 'dog' in caps[i]:\n",
        "    caps2.append(caps[i])\n",
        "    x3.append(x2[i])\n",
        "    img_path3.append(img_path2[i])\n",
        "  else:\n",
        "    continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hwu3DH8br-VV",
        "colab_type": "code",
        "outputId": "be7842e0-a65e-441a-8a78-ac246fd122f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(caps2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "mMVwlH91U9H_",
        "colab_type": "code",
        "outputId": "3948fdd0-22b7-4c67-e9ee-30e9137dd659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(img_path3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "CfMoBwlYsauB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x3 = np.array(x3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "brVS7NOY1kJo",
        "colab_type": "code",
        "outputId": "a4a938f6-3a77-4da0-b8f5-d55e87c12eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "words = [i.split() for i in caps2]\n",
        "unique = []\n",
        "for i in words:\n",
        "    unique.extend(i)\n",
        "\t\n",
        "unique = list(set(unique))\n",
        "len(unique)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3935"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "NNGxaTyq1SBI",
        "colab_type": "code",
        "outputId": "7f9a8155-fae7-4554-f982-682cd98dbd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word2idx = {val:(index+1) for index, val in enumerate(unique)}\n",
        "\n",
        "idx2word = {(index+1):val for index, val in enumerate(unique)}\n",
        "\n",
        "max_len = 0\n",
        "for c in caps2:\n",
        "    c = c.split()\n",
        "    if len(c) > max_len:\n",
        "        max_len = len(c)\n",
        "max_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "1FDSS6s12HnP",
        "colab_type": "code",
        "outputId": "fc534949-29ee-470a-f0b7-7c51b9aedd26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "caps2[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> a girl going into a wooden building <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "seID_0y12Hq3",
        "colab_type": "code",
        "outputId": "dbc2f5a7-63a4-44f8-b76a-ea920ba0a417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(unique)\n",
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3935"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "ZNPbcel22qaL",
        "colab_type": "code",
        "outputId": "30ce3c4e-8570-4c0f-e65d-4ddcd3e7a354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "n = np.zeros(vocab_size+1)\n",
        "n.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3936,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "vig-lrw93MoG",
        "colab_type": "code",
        "outputId": "e13ea103-a6a1-4b77-d02c-b85d5066fbe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word2idx['<end>']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3735"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "Y1xoMcA-B-Rf",
        "colab_type": "code",
        "outputId": "a8c8434f-8a88-4a91-fa6a-5a709c567571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(caps2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "by9QcsxV2qlW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = []\n",
        "y2 = []\n",
        "for k in range(len(caps2)):\n",
        "  t= [word2idx[i] for i in caps2[k].split()]\n",
        "  y.append(len(t))\n",
        "  while(len(t)<max_len):\n",
        "    t.append(word2idx['<end>'])\n",
        "  y2.append(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZWlD0j8L6Tac",
        "colab_type": "code",
        "outputId": "75b5c7a9-47ae-4a7c-9d38-d48bbb837e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(y2[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "rTWFtsoK4o6X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uZ0x-prCbPu6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical,np_utils\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D,Dropout, Activation, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Convolution2D, MaxPooling2D,Conv2D\n",
        "from keras.models import Model\n",
        "import random\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM , Bidirectional,Dropout\n",
        "from keras import backend as K\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras import regularizers\n",
        "from keras.layers import concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A6GxlAFyX3TK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "embedding_size = 300\n",
        "inp = Input(shape=(7,7,512))\n",
        "inp1 = Conv2D(512, (3,3), activation='relu')(inp)\n",
        "inp11 = MaxPooling2D(pool_size=(2, 2))(inp1)\n",
        "inp2 = Flatten()(inp11)\n",
        "img_emb = Dense(embedding_size, activation='relu') (inp2)\n",
        "img_emb2 = RepeatVector(max_len)(img_emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kpKZqlaObroG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inp2 = Input(shape=(max_len,))\n",
        "cap_emb = Embedding((vocab_size+1), embedding_size, input_length=max_len) (inp2)\n",
        "cap_emb2 = LSTM(256, return_sequences=True)(cap_emb)\n",
        "cap_emb3 = TimeDistributed(Dense(300)) (cap_emb2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZlfB3G5k6mSc",
        "colab_type": "code",
        "outputId": "820940e7-04d8-499a-e9e9-887cbc597ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "final1 = concatenate([img_emb2, cap_emb3])\n",
        "final2 = Bidirectional(LSTM(256, return_sequences=False))(final1)\n",
        "final3 = Dense(vocab_size+1)(final2)\n",
        "final4 = Activation('softmax')(final3)\n",
        "\n",
        "final_model = Model([inp, inp2], final4)\n",
        "final_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 7, 7, 512)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 5, 5, 512)    2359808     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 2, 2, 512)    0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 35, 300)      1180800     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 300)          614700      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 35, 256)      570368      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)  (None, 35, 300)      0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 35, 300)      77100       lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 35, 600)      0           repeat_vector_1[0][0]            \n",
            "                                                                 time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 512)          1755136     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3936)         2019168     bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 3936)         0           dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,577,080\n",
            "Trainable params: 8,577,080\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y3zG1mHD-j2f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "adam = Adam(lr = 0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u4nb0ll6faUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_model.compile(loss='categorical_crossentropy', optimizer = adam, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ThmNWEA6mYv",
        "colab_type": "code",
        "outputId": "5d1aa38b-e24c-4310-d06e-e6bfc5b871c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(2500):\n",
        "  x4 = []\n",
        "  x4_sent = []\n",
        "  y3 = []\n",
        "  shortlist_y = random.sample(range(len(y)-100),32)\n",
        "  for j in range(len(shortlist_y)):\n",
        "    for k in range(y[shortlist_y[j]]-1):\n",
        "      n = np.zeros(vocab_size+1)      \n",
        "      x4.append(x3[shortlist_y[j]])\n",
        "      pad_sent = pad_sequences([y2[shortlist_y[j]][:(k+1)]], maxlen=max_len, padding='post')\n",
        "      x4_sent.append(pad_sent)\n",
        "      n[y2[shortlist_y[j]][(k+1)]] = 1\n",
        "      y3.append(n)\n",
        "  x4 = np.array(x4)\n",
        "  x4_sent =np.array(x4_sent)\n",
        "  x4_sent = x4_sent.reshape(x4_sent.shape[0], x4_sent.shape[2])\n",
        "  y3 = np.array(y3) \n",
        "  if(i%100==0):\n",
        "    print(i)\n",
        "    final_model.fit([x4/12, x4_sent], y3, batch_size = 32, epochs = 3, verbose = 1)\n",
        "  else:\n",
        "    final_model.fit([x4/12, x4_sent], y3, batch_size = 32, epochs = 3, verbose = 0)  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/3\n",
            "361/361 [==============================] - 6s 17ms/step - loss: 8.2445 - acc: 0.0886\n",
            "Epoch 2/3\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 7.9514 - acc: 0.1524\n",
            "Epoch 3/3\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 7.0352 - acc: 0.1524\n",
            "100\n",
            "Epoch 1/3\n",
            "343/343 [==============================] - 3s 8ms/step - loss: 4.5160 - acc: 0.2012\n",
            "Epoch 2/3\n",
            "343/343 [==============================] - 3s 8ms/step - loss: 4.3533 - acc: 0.2187\n",
            "Epoch 3/3\n",
            "343/343 [==============================] - 3s 8ms/step - loss: 4.1801 - acc: 0.2274\n",
            "200\n",
            "Epoch 1/3\n",
            "350/350 [==============================] - 3s 8ms/step - loss: 4.0853 - acc: 0.2886\n",
            "Epoch 2/3\n",
            "350/350 [==============================] - 3s 8ms/step - loss: 3.9505 - acc: 0.2943\n",
            "Epoch 3/3\n",
            "350/350 [==============================] - 3s 8ms/step - loss: 3.7938 - acc: 0.3000\n",
            "300\n",
            "Epoch 1/3\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 4.1039 - acc: 0.2604\n",
            "Epoch 2/3\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 3.9380 - acc: 0.2776\n",
            "Epoch 3/3\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 3.7587 - acc: 0.3022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CBgkbTYcTGuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = np.zeros(max_len)\n",
        "p[0] = word2idx['<start>']\n",
        "l=-91"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YTcoDpLUkvX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im_path = '...'  # Path to test image file\n",
        "img1 = cv2.imread(im_path)\n",
        "plt.imshow(img1)\n",
        "plt.grid('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zSm3fN16galj",
        "colab_type": "code",
        "outputId": "321c5ce5-b00b-4540-c7cd-4f447341ace3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "caps2[l]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> the girl wearing the orange shirt and glasses is blowing a huge bubble <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {
        "id": "Bo-TL2C8TvTZ",
        "colab_type": "code",
        "outputId": "c4135c9c-7c04-4a93-dc0d-73175f1e3daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "x33= np.array(x3)\n",
        "for i in range(max_len-1):\n",
        "  pred= final_model.predict([x33[l].reshape(1,7,7,512)/12, p.reshape(1,max_len)])\n",
        "  pred2 = np.argmax(pred)\n",
        "  print(idx2word[pred2])\n",
        "  p[i+1] = pred2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n",
            "little\n",
            "girl\n",
            "in\n",
            "a\n",
            "pink\n",
            "shirt\n",
            "runs\n",
            "in\n",
            "a\n",
            "air\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n",
            "<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sy17cV4NHHmS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KCUGz0c91ejo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Beam search"
      ]
    },
    {
      "metadata": {
        "id": "NM7J9Cm61fhU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "beamsize = 3\n",
        "def get_top3(img, string_with_conf):\n",
        "     tokens, confidence = string_with_conf\n",
        "     p = np.zeros((1, max_len))\n",
        "     p[0, :len(tokens)] = np.array(tokens)\n",
        "     pred = final_model.predict([img.reshape(1,7,7,512)/12, p])\n",
        "     best_pred = list(np.argsort(pred)[0][-beamsize:])\n",
        "     best_confs = list(pred[0,best_pred])\n",
        "     top_best = [(tokens + list([best_pred[i]]), confidence*best_confs[i]) for i in range(beamsize)]\n",
        "     return top_best"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7c6zXwW51sav",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = word2idx['<start>']\n",
        "best_strings = [([start_token], 1)]\n",
        "for i in range(max_len):\n",
        "     new_best_strings = []\n",
        "     for string in best_strings:\n",
        "         strings = get_top3(x33[l], string)\n",
        "         new_best_strings.extend(strings) \n",
        "         best_strings = sorted(new_best_strings, key=lambda x: x[1], reverse=True)[:beamsize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SgueGPou1ygF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "     string = best_strings[i][0]\n",
        "     print('============')\n",
        "     for j in string:\n",
        "         print(idx2word[j])\n",
        "         if(idx2word[j]=='<end>'):\n",
        "             break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}